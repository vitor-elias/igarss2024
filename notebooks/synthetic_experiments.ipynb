{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy as sp\n",
    "# import contextily as cx\n",
    "\n",
    "import torch\n",
    "import pygsp\n",
    "import optuna\n",
    "import joblib\n",
    "import gc\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter, StrMethodFormatter, FormatStrFormatter, FuncFormatter\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, auc\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn.models import GraphUNet\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.utils import to_networkx, grid\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from importlib import reload\n",
    "from pyprojroot import here\n",
    "ROOT_DIR = str(here())\n",
    "insar_path = ROOT_DIR + \"/data/raw/insar/\"\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "matplotlib.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "# import dario.models.mismatch_analysis as mma\n",
    "# mma = reload(mma)\n",
    "\n",
    "# Function definitions\n",
    "\n",
    "def plot_anim(outputs, epochs):\n",
    "    def generate_matrix(epoch):\n",
    "        out = outputs[epoch][2].detach().numpy().reshape(28,28)\n",
    "        inp = outputs[epoch][1].numpy().reshape(28,28)\n",
    "\n",
    "        out = np.c_[inp,out]\n",
    "        return out #np.abs(out-inp)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    def init():\n",
    "        ax.clear()\n",
    "        plt.close()\n",
    "\n",
    "    def update(frame):\n",
    "        matrix = generate_matrix(frame)  # Generate the matrix for the current frame\n",
    "        ax.imshow(matrix, cmap='gray', vmin=0, vmax=1)  # Update the plot with the new matrix\n",
    "        # Hide all ticks and tick labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_title(f'{frame}', fontdict={'color':'white'})\n",
    "        plt.close()\n",
    "\n",
    "    fps = 2\n",
    "    ani = FuncAnimation(fig, update, frames=range(epochs), interval=1000/fps, repeat=True, blit=False, init_func=init)\n",
    "    return ani\n",
    "\n",
    "def roc_params(metric, label, interp=True):\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "    thr = []\n",
    "    thr_list = list(np.linspace(0, metric.max(),1001))\n",
    "\n",
    "    fp = 1\n",
    "    ind = 0\n",
    "    while fp > 0:\n",
    "        threshold = thr_list[ind]\n",
    "        ind += 1\n",
    "\n",
    "        y = (metric>threshold)\n",
    "        tn, fp, fn, tp = confusion_matrix(label, y).ravel()\n",
    "\n",
    "        fpr.append( fp/(tn + fp) )\n",
    "        tpr.append( tp/(tp + fn) )\n",
    "        thr.append( threshold )\n",
    "\n",
    "    while tp > 0:\n",
    "        threshold = thr_list[ind]\n",
    "        ind += 1\n",
    "        y = (metric>threshold)\n",
    "        tn, fp, fn, tp = confusion_matrix(label, y).ravel()\n",
    "\n",
    "    \n",
    "    fpr = fpr[::-1]\n",
    "    tpr = tpr[::-1]\n",
    "    thr = thr[::-1]\n",
    "\n",
    "    if interp:\n",
    "        fpr_base = np.linspace(0, 1, 101)\n",
    "        tpr = list(np.interp(fpr_base, fpr, tpr))\n",
    "        thr = list(np.interp(fpr_base, fpr, thr))\n",
    "        fpr = list(fpr_base)\n",
    "\n",
    "    fpr.insert(0, 0)\n",
    "    tpr.insert(0, 0)\n",
    "    thr.insert(0, threshold)\n",
    "\n",
    "    return tpr, fpr, thr\n",
    "\n",
    "def compute_auc(tpr, fpr):\n",
    "    auc = 0\n",
    "    for i in range(1, len(fpr)):\n",
    "        auc += (fpr[i] - fpr[i - 1]) * (tpr[i] + tpr[i - 1]) / 2\n",
    "    return auc\n",
    "\n",
    "# def detection(df_metrics, column_name='wse', threshold_min=1000, threshold_max=np.inf, selector='group',\n",
    "#               detection_param='detection_sum', detection_param_threshold=None):\n",
    "#     # df_relevant contains data from nodes that, at some point, have lower<=wse<=upper, and their neighbors.\n",
    "#     # nodes are put into groups if they are close to each other.\n",
    "\n",
    "#     if detection_param_threshold is None:\n",
    "#         detection_param_threshold = df_metrics.timestamp.nunique()//2\n",
    "\n",
    "#     df_relevant = mma.relevant_neighborhood(df_metrics, column_name=column_name,\n",
    "#                                             lower=threshold_min, upper=threshold_max,\n",
    "#                                             only_relevant=True, return_df=True, plot=False, filter_dates=False)\n",
    "\n",
    "#     # Treating disconnected nodes as individual groups. Assining new values\n",
    "#     new_group_values = df_relevant.query('group==0').pid.factorize()[0] + df_relevant.group.max()+1\n",
    "#     df_relevant.loc[df_relevant.group==0, 'group'] = new_group_values\n",
    "\n",
    "\n",
    "#     df_relevant['detection'] = (df_relevant[column_name]>=threshold_min) & (df_relevant[column_name]<=threshold_max)\n",
    "#     df_detection = df_relevant.groupby('pid').agg({column_name:['max','mean'],\n",
    "#                                                     'detection':['sum',mma.consecutive_ones],\n",
    "#                                                     'group':'mean'}).reset_index()\n",
    "\n",
    "#     df_detection.columns = [f\"{level1}_{level2}\" if level2 else level1 for level1, level2 in df_detection.columns]\n",
    "#     df_detection.rename({'group_mean':'group'}, axis=1, inplace=True)\n",
    "\n",
    "#     query = f'{detection_param}>{detection_param_threshold}'\n",
    "#     selected = df_detection.query(query)[selector].unique()\n",
    "\n",
    "#     return df_relevant, selected\n",
    "\n",
    "# def skew(df):\n",
    "#     return np.abs(sp.stats.skew(df.mean_velocity))\n",
    "\n",
    "\n",
    "# def compute_metric(df_test, cut=2, radius=15):\n",
    "\n",
    "#     df_metrics = []\n",
    "#     for cluster in sorted(df_test.cluster.unique()):\n",
    "\n",
    "#         df, nodes = mma.treat_nodes(df_test.query('cluster==@cluster'))\n",
    "#         G, nodes['subgraph'] = mma.NNGraph(nodes, radius=radius, subgraphs=True)\n",
    "\n",
    "#         df_metrics_cluster = []\n",
    "#         for sub_index in sorted(nodes.subgraph.unique())[1:]:\n",
    "\n",
    "#             subnodes = nodes.query('subgraph==@sub_index').copy()\n",
    "#             subdf = df[df.pid.isin(subnodes.pid)].copy()\n",
    "\n",
    "#             G = mma.NNGraph(subnodes, radius=radius)\n",
    "\n",
    "#             w, V = np.linalg.eigh(G.L.toarray())\n",
    "#             wh = np.ones(G.N)\n",
    "#             wh[w<cut] = 0\n",
    "#             Hh = V @ np.diag(wh) @ V.T\n",
    "\n",
    "#             smoothed = subdf[['pid', 'timestamp', 'smoothed' ]].pivot(index='pid', columns='timestamp')\n",
    "\n",
    "#             subdf['hf'] = np.abs((Hh @ smoothed.values).reshape((-1,), order='C'))\n",
    "\n",
    "#             df_metrics_cluster.append(subdf)\n",
    "\n",
    "#         df_metrics_cluster = pd.concat(df_metrics_cluster)\n",
    "#         df_metrics.append(df_metrics_cluster)\n",
    "\n",
    "#     df_metrics = pd.concat(df_metrics)\n",
    "#     return df_metrics\n",
    "\n",
    "\n",
    "# def hfilter(G, cut=2):\n",
    "#     L = G.L.toarray()\n",
    "#     w, V = np.linalg.eigh(L)\n",
    "#     wh = np.ones(G.N)\n",
    "#     wh[w<cut] = 0\n",
    "#     Hh = V @ np.diag(wh) @ V.T\n",
    "#     return Hh\n",
    "\n",
    "# def matplotlib_roc(save=None, ax=None):\n",
    "#     matplotlib.rcParams.update({'font.size': 20})\n",
    "#     matplotlib.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "#     if ax is None:\n",
    "#         fig, ax = plt.subplots(figsize=(12,5))\n",
    "#     # sc = ax.scatter(fpr, tpr, c=thr, cmap='viridis', label='Threshold')\n",
    "#     sc = ax.plot(fpr, tpr, linestyle='dotted', linewidth=1, color='black')\n",
    "\n",
    "#     # # Colorbar\n",
    "#     # cbar = plt.colorbar(sc, ax=ax)\n",
    "#     # cbar.set_label('Threshold', rotation=270, labelpad=15)\n",
    "\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     # plt.grid()\n",
    "#     # plt.tight_layout()\n",
    "\n",
    "#     if save is not None:\n",
    "#         plt.savefig(save, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igarss-REga8jWa-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
