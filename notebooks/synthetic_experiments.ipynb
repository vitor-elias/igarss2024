{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy as sp\n",
    "# import contextily as cx\n",
    "\n",
    "import torch\n",
    "import pygsp\n",
    "import optuna\n",
    "import joblib\n",
    "import gc\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter, StrMethodFormatter, FormatStrFormatter, FuncFormatter\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn.models import GraphUNet\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx, grid\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pyprojroot import here\n",
    "ROOT_DIR = str(here())\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "matplotlib.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "# Function definitions\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph U-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "\n",
    "class Args(argparse.Namespace):\n",
    "    n_epochs = [40,60,80,100]\n",
    "    n_trials = 50\n",
    "    learning_rate = [1e-3, 1e-2, 1e-1]\n",
    "    penalty_rate = [1e-15, 1e-5, 1e-4, 1e-2, 1e-1]\n",
    "    hidden_channels = [2, 3, 5]\n",
    "    depth = [2, 3, 5]\n",
    "    pool_ratios = [0.2, 0.3, 0.5]\n",
    "\n",
    "    log_dir=ROOT_DIR + '/models/outputs/optuna_gunet/'\n",
    "\n",
    "args = Args()\n",
    "\n",
    "\n",
    "for graph_size in [5, 10, 25, 50, 100, 150, 200]:\n",
    "    print(f'GRAPH SIZE: {graph_size}')\n",
    "\n",
    "    def train_model(model, n_epochs, learning_rate, penalty_rate):\n",
    "\n",
    "        torch.manual_seed(0)\n",
    "        loss_function = torch.nn.MSELoss() \n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                    lr = learning_rate,\n",
    "                                    weight_decay = penalty_rate)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        auc = []\n",
    "\n",
    "        for seed in range(20):\n",
    "\n",
    "            print(f'seed:{seed}')\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            G = generate_synthetic_graph(N=graph_size)\n",
    "            edge_index = torch.tensor(np.array(np.nonzero(G.A.toarray())), dtype=torch.long)\n",
    "\n",
    "            data, label = generate_data(G, size=20)\n",
    "\n",
    "            data = scaler.fit_transform(data)\n",
    "            label_vector = label.reshape((-1,), order='F')\n",
    "\n",
    "            error = []\n",
    "            \n",
    "            for snap in range(data.shape[1]):\n",
    "\n",
    "                # GRAPH UNET PART\n",
    "                x = torch.Tensor(data[:,snap]).reshape(-1,1)\n",
    "\n",
    "                model.reset_parameters()\n",
    "\n",
    "                epochs = n_epochs\n",
    "                outputs = []\n",
    "                losses = []\n",
    "                for epoch in range(epochs):\n",
    "                            \n",
    "                    reconstructed = model(x, edge_index)     # Output of Autoencoder\n",
    "                    loss = loss_function(reconstructed, x)    # Calculating the loss function\n",
    "                    \n",
    "                    optimizer.zero_grad() # The gradients are set to zero,\n",
    "                    loss.backward() # the gradient is computed and stored.\n",
    "                    optimizer.step() # .step() performs parameter update\n",
    "\n",
    "                    # Storing the losses in a list for plotting\n",
    "                    losses.append(loss)\n",
    "                    outputs.append((epoch, x, reconstructed))\n",
    "\n",
    "                error_snap = np.abs(reconstructed.detach() - x).numpy().flatten()\n",
    "                error.extend(error_snap)\n",
    "                \n",
    "            error = np.array(error).reshape((-1,))\n",
    "            tpr, fpr, thr = roc_params(error, label_vector, interp=True)\n",
    "            auc.append(compute_auc(tpr,fpr))\n",
    "\n",
    "        return np.mean(auc)        \n",
    "        \n",
    "        \n",
    "    def objective(trial):\n",
    "        gc.collect()\n",
    "\n",
    "        n_epochs = trial.suggest_categorical('n_epochs', args.n_epochs)\n",
    "        learning_rate = trial.suggest_categorical('learning_rate', args.learning_rate)\n",
    "        penalty_rate = trial.suggest_categorical('penalty_rate', args.penalty_rate)\n",
    "        hidden_channels = trial.suggest_categorical('hidden_channels', args.hidden_channels)\n",
    "        depth = trial.suggest_categorical('depth', args.depth)\n",
    "        pool_ratios = trial.suggest_categorical('pool_ratios', args.pool_ratios)\n",
    "\n",
    "        print(f\"INFO: Trial number: {trial.number}\")\n",
    "        print(f\"INFO: Learning rate: {learning_rate}\")\n",
    "        print(f\"INFO: Penalty rate: {penalty_rate}\")\n",
    "        print(f\"INFO: Hidden_channels: {hidden_channels}\")\n",
    "        print(f\"INFO: Depth: {depth}\")\n",
    "        print(f\"INFO: Pool ratios: {pool_ratios}\")\n",
    "        print(f\"INFO: n_epochs: {n_epochs}\")\n",
    "\n",
    "        model = GraphUNet(1, hidden_channels, 1, depth, pool_ratios)\n",
    "\n",
    "        return train_model(model, n_epochs, learning_rate, penalty_rate)\n",
    "\n",
    "\n",
    "    if not os.path.exists(args.log_dir):\n",
    "        os.makedirs(args.log_dir,exist_ok=True)\n",
    "\n",
    "    study = optuna.create_study(sampler=TPESampler(),\n",
    "                                direction='maximize',\n",
    "                                pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=24, interval_steps=6))\n",
    "\n",
    "    log_file = args.log_dir + f'optimization_logs_{graph_size}.pkl'\n",
    "    if os.path.isfile(log_file):\n",
    "        study = joblib.load(log_file)\n",
    "\n",
    "    study.optimize(objective, n_trials=args.n_trials, gc_after_trial=True)\n",
    "    joblib.dump(study, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load(\"../models/outputs/optuna_gunet/optimization_logs.pkl\").trials_dataframe().sort_values('value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igarss-REga8jWa-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
